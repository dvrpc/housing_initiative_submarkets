df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
df <- scale(df)
pam(df, 8,, metric = "euclidean", stand = FALSE)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
df <- scale(df)
pam(df, 8, metric = "euclidean", stand = FALSE)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
df <- scale(df)
pam(df, 8, metric = "euclidean", stand = TRUE)
wbPam <- pam(x=df, k=8, + keep.diss=TRUE, keep.data=TRUE)
wbPam <- pam(x=df, k=8, keep.diss=TRUE, keep.data=TRUE)
View(df)
library(dplyr)
library(factoextra)
library(cluster)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
# Find missing values
list_na <- colnames(df)[apply(df, 2, anyNA)]
list_na
library(dplyr)
library(factoextra)
library(cluster)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
# Find missing values
list_na <- colnames(df)[apply(df, 2, anyNA)]
list_na
# Impute missing values
median_missing <- apply(df[,colnames(df) %in% list_na],
2,
median,
na.rm = TRUE)
df_impute_median < -data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
median(x, na.rm = TRUE),
x)))
print(df_impute_median)
median_missing <- apply(df[,colnames(df) %in% list_na],
2,
median,
na.rm = TRUE)
df_impute_median < -data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
median(x, na.rm = TRUE),
x)))
print(df_impute_median)
# install.packages("dplyr")
# install.packages("tidyverse")
# install.packages("magrittr")
# install.packages("pipeR")
# install.packages("factoextra")
# install.packages("cluster")
library(dplyr)
library(factoextra)
library(cluster)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
# Find missing values
list_na <- colnames(df)[apply(df, 2, anyNA)]
list_na
# Impute missing values
median_missing <- apply(df[,colnames(df) %in% list_na],
2,
median,
na.rm = TRUE)
df_impute_median < -data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
mean(x, na.rm = TRUE),
x)))
print(df_impute_median)
df_impute_median < -data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
mean(x, na.rm = TRUE),
x)))
df_impute_median <- data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
mean(x, na.rm = TRUE),
x)))
View(df_impute_median)
df_impute_median <- data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
median(x, na.rm = TRUE),
x)))
df_scale <- scale(df_impute_median)
wbPam <- pam(x=df_scale, k=8, keep.diss=TRUE, keep.data=TRUE)
View(wbPam)
gap_stat <- clusGap(df_scale,
FUN = pam,
K.max = 10,
B = 50)
fviz_gap_stat(gap_stat)
library(dplyr)
library(factoextra)
library(cluster)
df <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", colClasses=c("GEOID"="character", "year"="character"), row.names="GEOID")
df <- select(df, -c(year, HH_TOT, POP_TOT, UNIT_MIS))
# Find missing values
list_na <- colnames(df)[apply(df, 2, anyNA)]
list_na
# Impute missing values
df_impute_median <- data.frame(
sapply(
df,
function(x) ifelse(is.na(x),
median(x, na.rm = TRUE),
x)))
print(df_impute_median)
# Scale dataframe
df_scale <- scale(df_impute_median)
wbPam <- pam(x=df_scale, k=8, keep.diss=TRUE, keep.data=TRUE)
gap_stat <- clusGap(df_scale,
FUN = pam,
K.max = 15,
B = 50)
fviz_gap_stat(gap_stat)
View(df_impute_median)
# Last updated: 06/10/2022
# Purpose: This script runs a test LPA algorithm on ACS 5-Year Estimates at the census tract level.
# Install packages
# install.packages("tidyLPA")
install.packages("factoextra")
install.packages("cluster")
# Import packages
library(dplyr)
library(tidyverse)
test_result <- acs2020 %>%
single_imputation() %>%
scale() %>%
estimate_profiles(10)
library(dplyr)
test_result <- acs2020 %>%
single_imputation() %>%
scale() %>%
estimate_profiles(10)
# Last updated: 06/10/2022
# Purpose: This script runs a test LPA algorithm on ACS 5-Year Estimates at the census tract level.
# Install packages
# install.packages("tidyLPA")
install.packages("factoextra")
install.packages("cluster")
# Import packages
library(dplyr)
library(tidyverse)
library(tidyLPA)
library(factoextra)
library(cluster)
# Import dataset
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names=1)
acs2020 <- subset(acs2020, select = -c(year, POP_TOT, HH_TOT, UNIT_MIS, HHI_U35, HHI_3575, HHI_75100, HHI_100P, HHI_150P, THREE_BR))
acs2020 <- acs2020 %>%
mutate_if(is.numeric, function(x) ifelse(is.na(x), median(x, na.rm = T), x))
results <- acs2020 %>%
single_imputation() %>%
estimate_profiles(7:15) %>%
print(results)
test_result <- acs2020 %>%
single_imputation() %>%
scale() %>%
estimate_profiles(10)
install.packages("cluster")
View(test_result)
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(m3)
# Subset columns
reduced_df <- export_1[myVars2]
# Append index
rownames(reduced_df) <- row.names(acs2020)
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")
# ----
# Test to see if the clusters are the same with another run through. they were the same.
# Export 2
m4 <- acs2020 %>%
estimate_profiles(8)
export_2 <- get_data(m4)
write.csv(export_2, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_2.csv")
View(export_1)
View(export_2)
View(reduced_df)
View(reduced_df)
View(reduced_df)
# install.packages("tidyLPA")
# install.packages("magrittr")
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(m3)
# Subset columns
reduced_df <- export_1[myVars2]
# Append index
rownames(reduced_df) <- tracts
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")
# ----
# Test to see if the clusters are the same with another run through. they were the same.
# Export 2
m4 <- acs2020 %>%
estimate_profiles(8)
export_2 <- get_data(m4)
write.csv(export_2, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_2.csv")
View(grouped_df)
View(reduced_df)
install.packages("tibble")
library(tidyLPA)
library(dplyr)
library(magrittr)
library(tibble)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
View(reduced_df)
library(tibble)
library(tidyLPA)
library(dplyr)
library(magrittr)
library(tibble)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(m3)
# Subset columns
reduced_df <- export_1[myVars2] %>%
rownames_to_column(var = "Tract") %>%
head
# Append index
rownames(reduced_df) <- tracts
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")
# ----
# Test to see if the clusters are the same with another run through. they were the same.
# Export 2
m4 <- acs2020 %>%
estimate_profiles(8)
export_2 <- get_data(m4)
write.csv(export_2, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_2.csv")
View(reduced_df)
View(export_1)
View(reduced_df)
View(acs2020)
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", header = TRUE)%>%
column_to_rownames(., var = "Tract")
View(acs2020)
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", header = TRUE)%>%
column_to_rownames(., var = "GEOID")
View(acs2020)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
View(acs2020)
View(reduced_df)
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(m3)
# Subset columns
reduced_df <- export_1[myVars2]
# Append index
rownames(reduced_df) <- tracts
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")
# ----
# Test to see if the clusters are the same with another run through. they were the same.
# Export 2
m4 <- acs2020 %>%
estimate_profiles(8)
export_2 <- get_data(m4)
write.csv(export_2, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_2.csv")
View(reduced_df)
View(grouped_df)
View(grouped_df)
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
drop(-c(Group.1))
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))
View(grouped_df)
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))%>%
rownames_to_column(., Class)
View(grouped_df)
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))%>%
rownames_to_column(., "Class")
View(grouped_df)
View(grouped_df)
# install.packages("tidyLPA")
# install.packages("magrittr")
library(tidyLPA)
library(dplyr)
library(magrittr)
acs2020 <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020[myVars]
tracts <- row.names(acs2020)
# getting median of each column using apply()
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
# imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
acs2020
# Export 1
m3 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(m3)
# Subset columns
reduced_df <- export_1[myVars2]
# Append index
rownames(reduced_df) <- tracts
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))
# ----
# Test to see if the clusters are the same with another run through. they were the same.
# Export 2
m4 <- acs2020 %>%
estimate_profiles(8)
export_2 <- get_data(m4)
write.csv(export_2, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_2.csv")
View(grouped_df)
acs2020_raw <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
acs2020 <- acs2020_raw[myVars]
tracts <- row.names(acs2020)
View(acs2020)
# Get medians for the region
acs2020_medians <- acs2020[myVars] %>%
apply(2, FUN = median)
acs2020_medians <- acs2020 %>%
subset(select = c(myVars)) %>%
apply(2, FUN = median)
medians <- acs2020 %>%
subset(select = c(myVars)) %>%
apply(2, FUN = median)
acs2020_median <- data.frame(medians)
View(acs2020_median)
# Get medians of ACS 2020 data
medians <- acs2020 %>%
subset(select = c(myVars)) %>%
apply(2, FUN = median)
acs2020_median <- medians %>%
data.frame()
View(acs2020_median)
medians <- acs2020 %>%
subset(select = c(myVars)) %>%
apply(2, FUN = median())
acs2020_medians <- colMedians(acs2020, na.rm = TRUE)
install.packages("matrixStats")
library(matrixStats)
acs2020_medians <- colMedians(acs2020, na.rm = TRUE)
acs2020_medians <- colMedians(acs2020[myVars], na.rm = TRUE)
acs2020_medians <- median(acs2020[myVars])
acs2020_medians <- median(acs2020)
library(tidyLPA)
library(dplyr)
library(magrittr)
library(matrixStats)
# Import data
acs2020_raw <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020_raw[myVars]
tracts <- row.names(acs2020)
all_column_median <- apply(acs2020, 2, median, na.rm=TRUE)
median_df <- data.frame(all_column_median)
View(median_df)
acs2020_medians <- data.frame(all_column_median) %>%
rename(median = all_column_median)
View(acs2020_medians)
median <- apply(acs2020, 2, median, na.rm=TRUE)
acs2020_medians <- data.frame(median)
View(acs2020_medians)
write.csv(acs2020_medians, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\acs2020_medians.csv")
View(acs2020)
acs2020_raw <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
acs2020$GEOID <- rown.names(acs2020_raw)
acs2020$GEOID <- row.names(acs2020_raw)
View(acs2020)
# Import libraries
library(tidyLPA)
library(dplyr)
library(magrittr)
library(matrixStats)
# Import data
acs2020_raw <- read.csv("G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\ACS5_2020\\acs5_2020_variables.csv", row.names = 1, header = TRUE)
acs2020$GEOID <- row.names(acs2020_raw)
myVars <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P")
myVars2 <- c("HHINC_MED", "MED_HVAL", "RENT_MED", "TEN_RENT", "TEN_OWN", "VCY", "HHI_150P", "YB_59E", "YB_6099", "YB_00L", "UNIT_1", "UNIT_2to4", "UNIT_5P", "Class")
acs2020 <- acs2020_raw[myVars]
tracts <- row.names(acs2020)
# Create dataframe with the median value for each field
median <- apply(acs2020, 2, median, na.rm=TRUE)
acs2020_medians <- data.frame(median)
# Export dataframe
write.csv(acs2020_medians, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\acs2020_medians.csv")
# Imputing median value with NA
for(i in colnames(acs2020))
acs2020[,i][is.na(acs2020[,i])] <- all_column_median[i]
# Export 1
e1 <- acs2020 %>%
estimate_profiles(8)
export_1 <- get_data(e1)
# Subset columns
reduced_df <- export_1[myVars2]
# Append index
rownames(reduced_df) <- tracts
# Write csv
write.csv(reduced_df, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\lpa_results_1.csv")
# Group by cluster and get median
grouped_df <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))
View(grouped_df)
write.csv(acs2020_cluster_medians, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\cluster_medians.csv")
acs2020_cluster_medians <- aggregate(reduced_df, by = list(reduced_df$Class), FUN = "median")%>%
subset(select = -c(Group.1))
# Export cluster medians
write.csv(acs2020_cluster_medians, "G:\\Shared drives\\FY22 Regional Housing Initiative\\Data\\lpa_test_1\\cluster_medians.csv")
View(acs2020_medians)
View(acs2020_cluster_medians)
